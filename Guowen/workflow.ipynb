{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lai', 'wetness', 'treeSpecies', 'Sentinel_2A_492.4',\n",
      "       'Sentinel_2A_559.8', 'Sentinel_2A_664.6', 'Sentinel_2A_704.1',\n",
      "       'Sentinel_2A_740.5', 'Sentinel_2A_782.8', 'Sentinel_2A_832.8',\n",
      "       ...\n",
      "       'w2491', 'w2492', 'w2493', 'w2494', 'w2495', 'w2496', 'w2497', 'w2498',\n",
      "       'w2499', 'w2500'],\n",
      "      dtype='object', length=2114)\n",
      "66\n",
      "Nan values distribution statistics: {'Sentinel_2A_704.1': 10, 'Sentinel_2A_740.5': 10, 'Sentinel_2A_782.8': 10, 'w469': 10, 'w470': 5, 'w471': 5, 'w473': 8, 'w474': 8}\n"
     ]
    }
   ],
   "source": [
    "csv_file = '../data/RtmSimulation_kickstart.csv'\n",
    "dataframe = pd.read_csv(csv_file, header=0, sep=',', index_col=0)\n",
    "print(dataframe.columns)\n",
    "print(dataframe.isnull().sum().sum())\n",
    "nan_result = dict(dataframe.isnull().sum())\n",
    "nan_result = {k: nan_result[k] for k in nan_result if nan_result[k] > 0}\n",
    "print(f'Nan values distribution statistics: {nan_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unrelated columns\n",
    "if 'treeSpecies' in dataframe.columns:\n",
    "    dataframe = dataframe.drop(columns=['treeSpecies'], axis=1)\n",
    "values = {k: dataframe[k].mean() for k in nan_result.keys()}\n",
    "dataframe.fillna(values, inplace=True) # change dataframe inplace, fill na values with mean value\n",
    "# sentinel columns number: 10, wavelength columns number: 2101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tsne method\n",
      "(1000, 3)\n",
      "(1000, 3)\n",
      "(1000, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "use_another_tsne = False\n",
    "if use_another_tsne:\n",
    "    print('Using another tsne method')\n",
    "    tsne_model = TSNE(n_components=3, n_jobs=4, random_state=0)\n",
    "    embeddings = tsne_model.fit_transform(dataframe.iloc[:, 2:])\n",
    "    print(embeddings.shape)\n",
    "else:\n",
    "    print('Using default tsne method')\n",
    "    tsne_model = TSNE(n_components=3, learning_rate='auto', init='random', perplexity=30, random_state=0)\n",
    "    wavelength_feature_data = dataframe.iloc[:, 12:]\n",
    "    wavelength_embeddings = tsne_model.fit_transform(wavelength_feature_data)\n",
    "    print(wavelength_embeddings.shape)\n",
    "\n",
    "    sentinel_feature_data = dataframe.iloc[:, 2:12]\n",
    "    tsne_model.set_params(n_components=3, perplexity=5)\n",
    "    sentinel_embeddings = tsne_model.fit_transform(sentinel_feature_data)\n",
    "    print(sentinel_embeddings.shape)\n",
    "\n",
    "    embeddings = np.concatenate((sentinel_embeddings, wavelength_embeddings), axis=1)\n",
    "    # tsne_model.set_params(n_components=2, perplexity=10)\n",
    "    # embeddings = tsne_model.fit_transform(embeddings)\n",
    "    # print(embeddings.shape)\n",
    "\n",
    "wetness_features = dataframe.iloc[:, 1].values\n",
    "wetness_features = np.expand_dims(wetness_features, axis=1)\n",
    "embeddings = np.concatenate((embeddings, wetness_features), axis=1)\n",
    "print(embeddings.shape)\n",
    "\n",
    "labels = dataframe.iloc[:, 0].values\n",
    "labels = np.expand_dims(labels, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy using linear regression: 0.8275324923664742\n",
      "Testing accuracy using linear regression: 0.7895184061988203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/i2dl/lib/python3.9/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy using random forest: 0.9894795157885877\n",
      "Testing accuracy using random forest: 0.9026077986480521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/i2dl/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8997756721772292\n",
      "Training accuracy using MLP: 0.9413370581643905\n",
      "Testing accuracy using MLP: 0.8878431381927037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "train_embeddings, test_embeddings, train_labels, test_labels = train_test_split(embeddings, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "m = LinearRegression()\n",
    "m.fit(train_embeddings, train_labels)\n",
    "print('Training accuracy using linear regression:', m.score(train_embeddings, train_labels))\n",
    "print('Testing accuracy using linear regression:', m.score(test_embeddings, test_labels))\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=100, max_depth=100, random_state=42)\n",
    "m.fit(train_embeddings, train_labels)\n",
    "print('Training accuracy using random forest:', m.score(train_embeddings, train_labels))\n",
    "print('Testing accuracy using random forest:', m.score(test_embeddings, test_labels))\n",
    "\n",
    "m = MLPRegressor(hidden_layer_sizes=(1000, 100, 10), max_iter=1000, random_state=42, early_stopping=True)\n",
    "m.fit(train_embeddings, train_labels)\n",
    "print('Training accuracy using MLP:', m.score(train_embeddings, train_labels))\n",
    "print('Testing accuracy using MLP:', m.score(test_embeddings, test_labels))\n",
    "\n",
    "\n",
    "# Configurations:\n",
    "# Perplexity: 30, 10, 15, 40\n",
    "# use_another_tsne = False, sentinel_feature_embedding n_components=3, wavelength_feature_embedding n_components=3 -> MLP regressor: 0.903\n",
    "# use_another_tsne = False, sentinel_feature_embedding n_components=2, wavelength_feature_embedding n_components=3 -> RandomForest regressor: 0.893\n",
    "# use_another_tsne = False, sentinel_feature_embedding n_components=1, wavelength_feature_embedding n_components=3 -> RandomForest regressor: 0.895, MLP: 0.881"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i2dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
